{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# UseCase B : ingest pdf in a vectorDB & query 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context definition\n",
    "\n",
    "Neo4j is used as Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE - Wednesday 20 November à 16h14 et 54 secondes'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import neo4j\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def printDone():\n",
    "    # Obtenir la date et l'heure actuelle\n",
    "    maintenant = datetime.now()\n",
    "    # Formater la date dans le format souhaité\n",
    "    date_formatee = maintenant.strftime(\"DONE - %A %d %B à %Hh%M et %S secondes\")\n",
    "    # Retourner la date formatée\n",
    "    return date_formatee\n",
    "    \n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OLLAMA_URL\"] = \"http://ollama:11434\"\n",
    "os.environ[\"embedding_model\"] = \"nomic-embed-text\"\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"neo4j://neo4j:7687\"\n",
    "os.environ[\"NEO4J_URI_BOLT\"] = \"bolt://neo4j:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"strongPassword1\"\n",
    "os.environ[\"INDEX_NAME\"] = \"pdf_chunk\"\n",
    "os.environ[\"FULLTEXT_INDEX_NAME\"] = \"documentFullTextIndex\"\n",
    "os.environ[\"embbeded_dim\"] = \"1536\"\n",
    "\n",
    "os.environ[\"OLLAMA_MODELE_URL\"] = \"http://ollama:11434/v1/\"\n",
    "os.environ[\"LLM_MODEL\"] = \"llama3.2:3b\"\n",
    "\n",
    "pdf_path1 = \"/home/jovyan/datasets/cvss-v31-user-guide_r1.pdf\"\n",
    "pdf_path2 = \"/home/jovyan/datasets/ISO_SAE_21434_2021.pdf\"\n",
    "\n",
    "my_chunk_size = 600\n",
    "my_overlap = 100\n",
    "\n",
    "printDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULLTEXT_INDEX_NAME = os.environ[\"FULLTEXT_INDEX_NAME\"]\n",
    "URI =os.environ[\"NEO4J_URI\"]\n",
    "AUTH = (os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    "\n",
    "driver = neo4j.GraphDatabase.driver(URI, auth=AUTH)\n",
    "\n",
    "def create_fulltext_index():\n",
    "    query = \"\"\"\n",
    "    CREATE FULLTEXT INDEX documentFullTextIndex IF NOT EXISTS FOR (n:documents_import) ON EACH [n.file_name, n.info]\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        session.run(query)\n",
    "\n",
    "create_fulltext_index()\n",
    "\n",
    "driver.close()\n",
    "\n",
    "printDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy for text extraction & chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Based Chunking\n",
    "\n",
    "Document-based chunking simplifies large documents by breaking them into smaller, easier-to-handle sections based on their structure or content. Unlike other chunking methods that cut text into pieces at specific points, document-based chunking divides documents into sections like paragraphs or chapters, depending on how they’re organized. For example, a Markdown file would be chunked differently than a Python file or a JSON file because chunking is based on the type of file, not the number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE - Wednesday 20 November à 16h14 et 54 secondes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_documents(docPath, chunk_size, overlap):\n",
    "\n",
    "    def pdf_to_markdown(pdf_path, chunk_size, overlap):\n",
    "        # Ouvrir le fichier PDF\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        # Initialiser la liste des chunks\n",
    "        chunks = []\n",
    "        \n",
    "        # Parcourir chaque page\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            text = page.get_text(\"markdown\")\n",
    "            \n",
    "            # Diviser le texte en chunks avec recouvrement\n",
    "            start = 0\n",
    "            while start < len(text):\n",
    "                end = min(start + chunk_size, len(text))\n",
    "                chunk = text[start:end]\n",
    "                chunks.append(chunk)  # Ajouter chaque chunk à la liste des chunks\n",
    "                start += chunk_size - overlap\n",
    "\n",
    "        print(\"count of chunks created : \" + str(len(chunks)) )\n",
    "        \n",
    "        # Retourner la liste des chunks\n",
    "        return chunks\n",
    "    \n",
    "    pdf_markdown_chunks = pdf_to_markdown(docPath, chunk_size, overlap)\n",
    "    file_name = os.path.basename(docPath)\n",
    "\n",
    "    docs = []\n",
    "    for doc in pdf_markdown_chunks:\n",
    "        docs.append(Document(page_content=doc))\n",
    "    \n",
    "    for idx, doc in enumerate(docs):\n",
    "        doc.metadata[\"file_name\"] = file_name\n",
    "        doc.metadata[\"chunk_id\"] = idx\n",
    "\n",
    "    return docs\n",
    "\n",
    "printDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Embeddings engin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE - Wednesday 20 November à 16h14 et 54 secondes'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "embeddings_engin = OllamaEmbeddings(base_url=os.environ[\"OLLAMA_URL\"], model=os.environ[\"embedding_model\"])\n",
    "\n",
    "printDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate a Vector Index with PDF 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of chunks created : 116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DONE - Wednesday 20 November à 16h16 et 46 secondes'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_markdown1 = create_documents(pdf_path1, my_chunk_size, my_overlap)\n",
    "\n",
    "db = Neo4jVector.from_documents(chunks_markdown1, \n",
    "                                embeddings_engin, \n",
    "                                url=os.environ[\"NEO4J_URI\"], \n",
    "                                username=os.environ[\"NEO4J_USERNAME\"], \n",
    "                                password=os.environ[\"NEO4J_PASSWORD\"],\n",
    "                                database=\"neo4j\",\n",
    "                                index_name=os.environ[\"INDEX_NAME\"], \n",
    "                                node_label=\"documents_import\",\n",
    "                                text_node_property=\"info\",\n",
    "                                embedding_node_property=\"vector\",\n",
    "                                create_id_index=True,\n",
    ")\n",
    "\n",
    "printDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in existing Vector Index PDF 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of chunks created : 420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DONE - Wednesday 20 November à 16h22 et 03 secondes'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_markdown2 = create_documents(pdf_path2, my_chunk_size, my_overlap)\n",
    "\n",
    "db = Neo4jVector.from_documents(chunks_markdown2, \n",
    "                                embeddings_engin, \n",
    "                                url=os.environ[\"NEO4J_URI\"], \n",
    "                                username=os.environ[\"NEO4J_USERNAME\"], \n",
    "                                password=os.environ[\"NEO4J_PASSWORD\"],\n",
    "                                database=\"neo4j\",\n",
    "                                index_name=os.environ[\"INDEX_NAME\"], \n",
    "                                node_label=\"documents_import\",\n",
    "                                text_node_property=\"info\",\n",
    "                                embedding_node_property=\"vector\",\n",
    "                                create_id_index=True,\n",
    ")\n",
    "\n",
    "printDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW INDEXES YIELD name, type, entityType, labelsOrTypes, properties, state\n",
    "# MATCH (n:documents_import) WITH n.file_name AS file_name, count(n) AS count RETURN file_name, count\n",
    "# MATCH (n:documents_import) DETACH DELETE n\n",
    "# DROP INDEX pdf_chunk\n",
    "\n",
    "# 116 chunks, 116 in DB\n",
    "# 420 chunks, 418 in DB (!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
